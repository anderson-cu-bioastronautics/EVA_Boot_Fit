{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pclpy import pcl as pcl2\n",
    "import pcl\n",
    "import pcl.pcl_visualization\n",
    "import time\n",
    "import numpy as np\n",
    "from open3d import *\n",
    "from open3d import JVisualizer\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depthFrametoPC(depth, rgb, cameraIntrinsics, poseMat):\n",
    "    #starttime = time.time()\n",
    "    [height,width] = np.array(depth.shape)\n",
    "    #[height, width] = [depthFrame.get_height(), depthFrame.get_width()]\n",
    "    #depth = np.asanyarray(depthFrame.get_data())\n",
    "    #rgb = np.asanyarray(colorFrame.get_data())\n",
    "    ##time1 = time.time()\n",
    "    nx = np.linspace(0, width-1, width)\n",
    "    ny = np.linspace(0, height-1, height)\n",
    "    u, v = np.meshgrid(nx, ny)\n",
    "    x = (u.flatten() - cameraIntrinsics['ppx'])/cameraIntrinsics['fx']\n",
    "    y = (v.flatten() - cameraIntrinsics['ppy'])/cameraIntrinsics['fy']\n",
    "    z = depth.flatten() / 1000\n",
    "    x = np.multiply(x,z)\n",
    "    y = np.multiply(y,z)\n",
    "    ##time2 = time.time()\n",
    "    #x = x[np.nonzero(z)]\n",
    "    #y = y[np.nonzero(z)]\n",
    "    #z = z[np.nonzero(z)]\n",
    "\n",
    "    rgbB = rgb[:,:,0].flatten().astype(int)\n",
    "    rgbG = rgb[:,:,1].flatten().astype(int)\n",
    "    rgbR = rgb[:,:,2].flatten().astype(int)\n",
    "    rgbPC = rgbR<<16|rgbG<<8|rgbB\n",
    "    ##time3=time.time()\n",
    "    points = np.asanyarray([x,y,z])\n",
    "\n",
    "    n = points.shape[1] \n",
    "    points_ = np.vstack((points, np.ones((1,n))))\n",
    "    points_trans_ = np.matmul(poseMat, points_)\n",
    "    points_transformed = np.true_divide(points_trans_[:3,:], points_trans_[[-1], :])\n",
    "    ##time4=time.time()\n",
    "    allPoints = np.asanyarray([points_transformed[0,:],points_transformed[1,:],points_transformed[2,:],rgbR/256,rgbG/256,rgbB/256]).T\n",
    "    ##times = np.array([time1,time2,time3,time4])-starttime\n",
    "    ##print(times)\n",
    "    return allPoints\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = 'loco5foot-1-25.pickle'\n",
    "file = open(filename, 'rb')\n",
    "#dataRead = []\n",
    "#cloud1 = pcl.PointCloud_PointXYZRGBA()\n",
    "#cloud2 = pcl.PointCloud_PointXYZRGBA()\n",
    "#visual = pcl.pcl_visualization.CloudViewing()\n",
    "#time.sleep(2)\n",
    "for i in range(1,60):\n",
    "    try:\n",
    "        frame = pickle.load(file) #this loads each frame in one at a time, this is where we can process each frame with the transformation matrix\n",
    "        #cloud = pcl.PointCloud_PointXYZRGBA()\n",
    "        #cloud2 = pcl.PointCloud_PointXYZRGBA()\n",
    "        allPoints = np.empty((0,4))\n",
    "        #for (serial, [poseMat, rmsdValue]) in self.devicesTransformation.items():\n",
    "        pointClouds = []\n",
    "        j=0\n",
    "        for camera,deviceData in frame.items():\n",
    "            #cloud = pcl.PointCloud_PointXYZRGBA()\n",
    "            pcd = PointCloud()\n",
    "            depthFrame = deviceData['depth']\n",
    "            colorFrame = deviceData['color']\n",
    "            cameraIntrinsics = deviceData['intrinsics']\n",
    "            poseMat = deviceData['poseMat']\n",
    "            points = depthFrametoPC(depthFrame, colorFrame, cameraIntrinsics, poseMat)\n",
    "            pcd.points=Vector3dVector(points[:,0:3])\n",
    "            pcd.colors=Vector3dVector(points[:,3:6])\n",
    "            pointClouds = np.append(pointClouds,pcd)#cloud.from_array(points.astype('float32'))\n",
    "            #visual.ShowColorACloud(cloud)\n",
    "            j += 1\n",
    "            #print(j)\n",
    "            #allPoints = np.append(allPoints, points,axis=0)\n",
    "        #cloud.from_array(allPoints.astype('float32'))\n",
    "        i+=1\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "draw_geometries([pointClouds[i] for i in [0,2,5]])\n",
    "draw_geometries([pointClouds[i] for i in [1,3,4]])\n",
    "#source = pointClouds[0]\n",
    "#target = pointClouds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_geometries([pointClouds[i] for i in [0,1,2,3,4,5]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def draw_registration_result_original_color(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    source_temp.transform(transformation)\n",
    "    draw_geometries([source_temp, target])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Colored point cloud registration\n",
      "[50, 0.04, 0]\n",
      "3-1. Downsample with a voxel size 0.04\n",
      "3-2. Estimate normal.\n",
      "3-3. Applying colored point cloud registration\n",
      "RegistrationResult with fitness = 0.435331, inlier_rmse = 0.021291, and correspondence_set size of 138\n",
      "Access transformation to get result.\n",
      "3. Colored point cloud registration\n",
      "[50, 0.04, 0]\n",
      "3-1. Downsample with a voxel size 0.04\n",
      "3-2. Estimate normal.\n",
      "3-3. Applying colored point cloud registration\n",
      "RegistrationResult with fitness = 0.495798, inlier_rmse = 0.013102, and correspondence_set size of 118\n",
      "Access transformation to get result.\n",
      "3. Colored point cloud registration\n",
      "[50, 0.04, 0]\n",
      "3-1. Downsample with a voxel size 0.04\n",
      "3-2. Estimate normal.\n",
      "3-3. Applying colored point cloud registration\n",
      "RegistrationResult with fitness = 0.547468, inlier_rmse = 0.020111, and correspondence_set size of 173\n",
      "Access transformation to get result.\n",
      "3. Colored point cloud registration\n",
      "[50, 0.04, 0]\n",
      "3-1. Downsample with a voxel size 0.04\n",
      "3-2. Estimate normal.\n",
      "3-3. Applying colored point cloud registration\n",
      "RegistrationResult with fitness = 0.464615, inlier_rmse = 0.018900, and correspondence_set size of 151\n",
      "Access transformation to get result.\n",
      "3. Colored point cloud registration\n",
      "[50, 0.04, 0]\n",
      "3-1. Downsample with a voxel size 0.04\n",
      "3-2. Estimate normal.\n",
      "3-3. Applying colored point cloud registration\n",
      "RegistrationResult with fitness = 0.738739, inlier_rmse = 0.016530, and correspondence_set size of 164\n",
      "Access transformation to get result.\n"
     ]
    }
   ],
   "source": [
    "newPCs = copy.deepcopy(pointClouds)\n",
    "for i in range(1,6):\n",
    "    newPCs[i]=colorRegist(pointClouds[i], pointClouds[0])\n",
    "draw_geometries([i for i in newPCs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Point-to-plane ICP registration is applied on original point\n",
      "   clouds to refine the alignment. Distance threshold 0.02.\n",
      "RegistrationResult with fitness = 0.000000, inlier_rmse = 0.000000, and correspondence_set size of 0\n",
      "Access transformation to get result.\n"
     ]
    }
   ],
   "source": [
    "# draw initial alignment\n",
    "current_transformation = np.identity(4)\n",
    "draw_registration_result_original_color(\n",
    "        source, target, current_transformation)\n",
    "\n",
    "# point to plane ICP\n",
    "current_transformation = np.identity(4);\n",
    "print(\"2. Point-to-plane ICP registration is applied on original point\")\n",
    "print(\"   clouds to refine the alignment. Distance threshold 0.02.\")\n",
    "result_icp = registration_icp(source, target, 0.02,\n",
    "        current_transformation, TransformationEstimationPointToPlane())\n",
    "print(result_icp)\n",
    "draw_registration_result_original_color(\n",
    "        source, target, result_icp.transformation)\n",
    "#this doesn't seem to be necessary since it doesn't have any improvement over kabsch algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorRegist(source, target):# colored pointcloud registration\n",
    "    # This is implementation of following paper\n",
    "    # J. Park, Q.-Y. Zhou, V. Koltun,\n",
    "    # Colored Point Cloud Registration Revisited, ICCV 2017\n",
    "    voxel_radius = [ 0.04, 0.02, 0.01 ];\n",
    "    max_iter = [ 50, 30, 24 ];\n",
    "    current_transformation = np.identity(4)\n",
    "    print(\"3. Colored point cloud registration\")\n",
    "    for scale in range(3):\n",
    "        iter = max_iter[scale]\n",
    "        radius = voxel_radius[scale]\n",
    "        print([iter,radius,scale])\n",
    "\n",
    "        print(\"3-1. Downsample with a voxel size %.2f\" % radius)\n",
    "        source_down = voxel_down_sample(source, radius)\n",
    "        target_down = voxel_down_sample(target, radius)\n",
    "\n",
    "        print(\"3-2. Estimate normal.\")\n",
    "        estimate_normals(source_down, KDTreeSearchParamHybrid(\n",
    "                radius = radius * 2, max_nn = 30))\n",
    "        estimate_normals(target_down, KDTreeSearchParamHybrid(\n",
    "                radius = radius * 2, max_nn = 30))\n",
    "\n",
    "        print(\"3-3. Applying colored point cloud registration\")\n",
    "        result_icp = registration_colored_icp(source_down, target_down,\n",
    "                radius, current_transformation,\n",
    "                ICPConvergenceCriteria(relative_fitness = 1e-6,\n",
    "                relative_rmse = 1e-6, max_iteration = iter))\n",
    "        current_transformation = result_icp.transformation\n",
    "        print(result_icp)\n",
    "        source_temp = copy.deepcopy(source)\n",
    "        #print(np.asanyarray(source_temp.points))\n",
    "        source_temp.transform(result_icp.transformation)\n",
    "        #print(np.asanyarray(source_temp.points))\n",
    "        return source_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(0, PointCloud with 407040 points.), (1, PointCloud with 407040 points.), (2, PointCloud with 407040 points.), (3, PointCloud with 407040 points.), (4, PointCloud with 407040 points.), (5, PointCloud with 407040 points.)])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointClouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud0 = pcl.PointCloud()\n",
    "cloud1 = pcl.PointCloud()\n",
    "cloud2 = pcl.PointCloud()\n",
    "cloud3 = pcl.PointCloud()\n",
    "cloud4 = pcl.PointCloud()\n",
    "cloud5 = pcl.PointCloud()\n",
    "\n",
    "cloud0.from_array(pointClouds[0][:,0:3].astype('float32'))\n",
    "cloud1.from_array(pointClouds[1][:,0:3].astype('float32'))\n",
    "cloud2.from_array(pointClouds[2][:,0:3].astype('float32'))\n",
    "cloud3.from_array(pointClouds[3][:,0:3].astype('float32'))\n",
    "cloud4.from_array(pointClouds[4][:,0:3].astype('float32'))\n",
    "cloud5.from_array(pointClouds[5][:,0:3].astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icp1 = cloud0.make_IterativeClosestPoint()\n",
    "converged, transf, estimate1, fitness=icp1.icp(cloud0, cloud1)\n",
    "\n",
    "icp2 = cloud0.make_IterativeClosestPoint()\n",
    "converged, transf, estimate2, fitness=icp2.icp(cloud0, cloud2)\n",
    "\n",
    "icp3 = cloud0.make_IterativeClosestPoint()\n",
    "converged, transf, estimate3, fitness=icp3.icp(cloud0, cloud3)\n",
    "\n",
    "icp4 = cloud0.make_IterativeClosestPoint()\n",
    "converged, transf, estimate4, fitness=icp4.icp(cloud0, cloud4)\n",
    "\n",
    "icp5 = cloud0.make_IterativeClosestPoint()\n",
    "converged, transf, estimate5, fitness=icp5.icp(cloud0, cloud5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icp = cloud1.make_IterativeClosestPoint()\n",
    "icp.icp(cloud1, cloud2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual = pcl.pcl_visualization.CloudViewing()\n",
    "visual.ShowMonochromeCloud(cloud2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
